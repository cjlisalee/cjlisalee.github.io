
<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Chi-Jung Lee</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
	</head>
    <body class="is-preload">

		<!-- Nav -->
			<nav id="nav">
				<ul class="container">
					<li><a href="../index.html">Home</a></li>
					<li><a href="mailto:cl2358@cornell.edu">Contact</a></li>
				</ul>
			</nav>     
            
        <!-- Project -->
            <article id="project" class="wrapper style3">
				<div class="container">
                    <article class="box style3">
                        <div class="col-12">
                            <div class="col-8 col-7-large col-12-medium">
                                <h3><a href="#">EchoWrist: Continuous Hand Pose Tracking and Hand-Object Interaction Recognition Using Low-Power Active Acoustic Sensing On a Wristband</a></h3> 
                                <span><h5>CHI '24</h5></span>
                                    <p><strong>Chi-Jung Lee*</strong>, Ruidong Zhang*, Devansh Agarwal, Tianhong Catherine Yu, Vipin Gunda, Oliver Lopez, James Kim, Sicheng Yin, Boao Dong, Ke Li, Mose Sakashita, François Guimbretière, Cheng Zhang (*contributed equally)</p>
                                    <p>Our hands serve as a fundamental means of interaction with the world around us. Therefore, understanding hand poses and interaction contexts is critical for human-computer interaction (HCI). We present EchoWrist, a low-power wristband that continuously estimates 3D hand poses and recognizes hand-object interactions using active acoustic sensing. EchoWrist is equipped with two speakers emitting inaudible sound waves toward the hand. These sound waves interact with the hand and its surroundings through reflections and diffractions, carrying rich information about the hand's shape and the objects it interacts with. The information captured by the two microphones goes through a deep learning inference system that recovers hand poses and identifies various everyday hand activities. Results from the two 12-participant user studies show that EchoWrist is effective and efficient at tracking 3D hand poses and recognizing hand-object interactions. Operating at 57.9 mW, EchoWrist can continuously reconstruct 20 3D hand joints with MJEDE of 4.81 mm and recognize 12 naturalistic hand-object interactions with 97.6% accuracy.</p>
                                    <p>[<a href="../documents/EchoWrist.pdf">Paper</a>] [<a href="https://youtu.be/yCLDzKarIEo">Video</a>] [<a href="https://dl.acm.org/doi/10.1145/3613904.3642910">Digital Library</a>]</p>

                                    <iframe width="1120" height="630" src="https://youtu.be/yCLDzKarIEo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    </article>
                </div>
                        
            </article>
    </body>
</html>
